{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Atenção: **\n",
    "Utilize Java JDK 1.8 ou 11 e Apache Spark 2.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Caso receba mensagem de erro \"name 'sc' is not defined\", interrompa o pyspark e apague o diretório metastore_db no mesmo diretório onde está este Jupyter notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Spark MLLib - Sistema de Recomendação</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Descrição </strong>\n",
    "<ul style=\"list-style-type:square\">\n",
    "  <li>Também chamado de filtros colaborativos.</li>\n",
    "  <li>Analisa dados passados para compreender comportamentos de pessoas/entidades.</li>\n",
    "  <li>A recomendação é feita por similaridade de comportamento.</li>\n",
    "  <li>Recomendação baseada em usuários ou items.</li>\n",
    "  <li>Algoritmos de Recomendação esperam receber os dados em um formato específico: [user_ID, item_ID, score].</li>\n",
    "  <li>Score, também chamado rating, indica a preferência de um usuário sobre um item. Podem ser valores booleanos, ratings ou mesmo volume de vendas.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/18 00:33:52 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Spark Session - usada quando se trabalha com Dataframes no Spark\n",
    "spSession = SparkSession.builder.master(\"local\").appName(\"Kayo-SparkMLLib\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spSession.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1001,9001,10',\n",
       " '1001,9002,1',\n",
       " '1001,9003,9',\n",
       " '1002,9001,3',\n",
       " '1002,9002,5',\n",
       " '1002,9003,1',\n",
       " '1002,9004,10',\n",
       " '1003,9001,2',\n",
       " '1003,9002,6',\n",
       " '1003,9003,2',\n",
       " '1003,9004,9',\n",
       " '1003,9005,10',\n",
       " '1003,9006,8',\n",
       " '1003,9007,9',\n",
       " '1004,9001,9',\n",
       " '1004,9002,2',\n",
       " '1004,9003,8',\n",
       " '1004,9004,3',\n",
       " '1004,9010,10',\n",
       " '1004,9011,9',\n",
       " '1004,9012,8',\n",
       " '1005,9001,8',\n",
       " '1005,9002,3',\n",
       " '1005,9003,7',\n",
       " '1005,9004,1',\n",
       " '1005,9010,9',\n",
       " '1005,9011,10',\n",
       " '1005,9012,9',\n",
       " '1005,9013,8',\n",
       " '1005,9014,1',\n",
       " '1005,9015,1',\n",
       " '1006,9001,7',\n",
       " '1006,9002,4',\n",
       " '1006,9003,8',\n",
       " '1006,9004,1',\n",
       " '1006,9010,7',\n",
       " '1006,9011,6',\n",
       " '1006,9012,9']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carrega os dados no formato ALS (user, item, rating)\n",
    "ratingsRDD = sc.textFile(\"data/user-item.txt\")\n",
    "ratingsRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo as strings\n",
    "ratingsRDD2 = ratingsRDD.map(lambda l: l.split(',')).map(lambda l:(int(l[0]), int(l[1]), float(l[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 2:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Criando um Dataframe\n",
    "ratingsDF = spSession.createDataFrame(ratingsRDD2, [\"user\", \"item\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|user|item|rating|\n",
      "+----+----+------+\n",
      "|1001|9001|  10.0|\n",
      "|1001|9002|   1.0|\n",
      "|1001|9003|   9.0|\n",
      "|1002|9001|   3.0|\n",
      "|1002|9002|   5.0|\n",
      "|1002|9003|   1.0|\n",
      "|1002|9004|  10.0|\n",
      "|1003|9001|   2.0|\n",
      "|1003|9002|   6.0|\n",
      "|1003|9003|   2.0|\n",
      "|1003|9004|   9.0|\n",
      "|1003|9005|  10.0|\n",
      "|1003|9006|   8.0|\n",
      "|1003|9007|   9.0|\n",
      "|1004|9001|   9.0|\n",
      "|1004|9002|   2.0|\n",
      "|1004|9003|   8.0|\n",
      "|1004|9004|   3.0|\n",
      "|1004|9010|  10.0|\n",
      "|1004|9011|   9.0|\n",
      "+----+----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratingsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/18 00:42:00 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/08/18 00:42:00 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/08/18 00:42:01 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "# Construindo o modelo\n",
    "# ALS = Alternating Least Squares --> Algoritmo para sistema de recomendação, que otimiza a loss function \n",
    "# e funciona muito bem em ambientes paralelizados\n",
    "# Não são todos os algoritmos de ML que apresentam bom desempenho em sistemas paralelos (ALS, Random Forest)\n",
    "als = ALS(rank = 10, maxIter = 5)\n",
    "modelo = als.fit(ratingsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1001, features=[0.10471921414136887, -0.12986880540847778, -0.9920188784599304, -0.6670140624046326, 0.002714240225031972, -1.160642385482788, -0.0358116589486599, 0.6356903910636902, -0.0029970980249345303, -0.2793961465358734]),\n",
       " Row(id=1002, features=[0.519737184047699, 0.09015104919672012, 0.07795949280261993, 1.1141307353973389, 0.8528119921684265, 0.07211394608020782, 0.7324118614196777, 0.6625441908836365, -0.2170950025320053, -0.7342068552970886]),\n",
       " Row(id=1003, features=[0.2783157527446747, 0.14826028048992157, 0.37782737612724304, 0.6766780018806458, 1.1771079301834106, 0.16773365437984467, 0.26167353987693787, 0.5781129002571106, -0.5181673765182495, -0.2702103555202484]),\n",
       " Row(id=1004, features=[0.17526251077651978, -0.20905305445194244, -0.9899356961250305, -0.07294473052024841, 0.45437315106391907, -0.9831053614616394, 0.11612792313098907, 0.46997737884521484, -0.13534589111804962, -0.48477357625961304]),\n",
       " Row(id=1005, features=[0.15774418413639069, 0.2080664336681366, -0.17198243737220764, -0.5804587602615356, 0.027431799098849297, -0.7453188300132751, 0.10312586277723312, 1.0863269567489624, -0.029517970979213715, -0.24427784979343414]),\n",
       " Row(id=1006, features=[-0.0994071438908577, 0.05565008148550987, -0.07798679172992706, -0.853583574295044, 0.9602174758911133, -0.5325801372528076, -0.5946853160858154, 0.5436792969703674, -0.7014214396476746, 0.4622071087360382])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando o Affinity Score\n",
    "modelo.userFactors.orderBy(\"id\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user=1001, item=9003),\n",
       " Row(user=1001, item=9004),\n",
       " Row(user=1001, item=9005)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando um dataset de teste com usuários e items para rating\n",
    "testeDF = spSession.createDataFrame([(1001, 9003),(1001,9004),(1001,9005)], [\"user\", \"item\"])\n",
    "testeDF.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsões  \n",
    "# Quanto maior o Affinity Score, maior a probabilidade do usuário aceitar uma recomendação\n",
    "previsoes = (modelo.transform(testeDF).collect())\n",
    "previsoes"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
